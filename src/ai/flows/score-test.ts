
// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview An AI agent that scores a test based on AI-provided answers.
 *
 * - scoreTestWithAI - A function that handles the test scoring process using AI.
 * - ScoreTestWithAIInput - The input type for the scoreTestWithAI function.
 * - ScoreTestWithAIOutput - The return type for the scoreTestWithAI function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const QuestionSchema = z.object({
  question: z.string().describe('The text of the question.'),
  options: z.array(z.string()).describe('The possible answers to the question.'),
  answer: z.string().nullable().describe('The correct answer to the question provided by the initial extraction/generation. Null if unknown.'),
  userAnswer: z.string().nullable().describe('The user-selected answer to the question. Null if unanswered.'),
});

export type Question = z.infer<typeof QuestionSchema>;

const TestConfigurationSchema = z.object({
    isTimedTest: z.boolean(),
    durationMinutes: z.number(),
    enableNegativeMarking: z.boolean(),
    negativeMarkValue: z.number(),
});

const ScoreTestWithAIInputSchema = z.object({
  questions: z.array(QuestionSchema).describe('The list of questions with user answers and potentially AI-assigned correct answers.'),
  testConfiguration: TestConfigurationSchema.describe('Configuration settings for the test, including negative marking.'),
});

export type ScoreTestWithAIInput = z.infer<typeof ScoreTestWithAIInputSchema>;

const TestResultItemSchema = z.object({
    question: z.string().describe('The question text.'),
    correctAnswer: z.string().describe('The AI-determined correct answer.'),
    userAnswer: z.string().nullable().describe('The user-provided answer, or null if unanswered.'),
    isCorrect: z.boolean().describe('Whether the user answered correctly according to AI.'),
});

const ScoreTestWithAIOutputSchema = z.object({
  results: z.array(TestResultItemSchema),
  score: z.number().describe('The user score (number of correct answers, adjusted for negative marking if applicable).'),
  totalQuestions: z.number().describe('The total number of questions.'),
});

export type ScoreTestWithAIOutput = z.infer<typeof ScoreTestWithAIOutputSchema>;

export async function scoreTestWithAI(input: ScoreTestWithAIInput): Promise<ScoreTestWithAIOutput> {
  return scoreTestWithAIFlow(input);
}

const scoreTestPrompt = ai.definePrompt({
  name: 'scoreTestPrompt',
  input: {schema: ScoreTestWithAIInputSchema},
  output: {
    schema: z.object({ // The direct output from LLM will only be the results array. Score is calculated after.
      results: z.array(TestResultItemSchema),
    }),
  },
  prompt: `You are an AI test scoring assistant. Given a list of questions and the user's answers,
you will determine the correct answers and compare them to the user's answers.
If a question already has a pre-assigned correct answer (from the 'answer' field in the input questions array), prioritize that as the correct answer.
Otherwise, determine the correct answer based on your knowledge.

Here are the questions and user answers:
{{#each questions}}
Question: {{question}}
Options: {{options}}
{{#if answer}}Pre-assigned Correct Answer: {{answer}}{{/if}}
User Answer: {{userAnswer}}
---
{{/each}}

Provide the results in the following JSON format for the "results" array only:
[
  {
    "question": "The question text.",
    "correctAnswer": "The AI-determined correct answer (must be one of the provided options).",
    "userAnswer": "The user-provided answer, or null if unanswered.",
    "isCorrect": true/false (based on your determination of correctness)
  }
  // ... more results
]

Ensure that the 'correctAnswer' value is always one of the options available for the question.
Focus only on providing the "results" array. The final score will be calculated separately.
`,
});

const scoreTestWithAIFlow = ai.defineFlow(
  {
    name: 'scoreTestWithAIFlow',
    inputSchema: ScoreTestWithAIInputSchema,
    outputSchema: ScoreTestWithAIOutputSchema,
  },
  async (input: ScoreTestWithAIInput): Promise<ScoreTestWithAIOutput> => {
    const {output} = await scoreTestPrompt(input); // LLM output is { results: TestResultItem[] }

    if (!output || !output.results) {
      // Handle cases where LLM might return an unexpected structure or nothing
      const fallbackResults = input.questions.map(q => ({
        question: q.question,
        correctAnswer: q.answer || "AI could not determine", // Use provided answer if available
        userAnswer: q.userAnswer,
        isCorrect: (q.userAnswer !== null && q.userAnswer === q.answer), // Basic correctness if answer provided
      }));
      return {
        results: fallbackResults,
        score: fallbackResults.reduce((acc, r) => acc + (r.isCorrect ? 1 : 0), 0),
        totalQuestions: input.questions.length,
      };
    }

    // Calculate score based on LLM results and negative marking
    let calculatedScore = 0;
    const finalResults = output.results.map(result => {
      const questionDetails = input.questions.find(q => q.question === result.question);
      let currentCorrectAnswer = result.correctAnswer;

      // Ensure the LLM's correctAnswer is one of the options
      if (questionDetails && !questionDetails.options.includes(result.correctAnswer)) {
        // If LLM hallucinates an answer not in options, try to use pre-assigned or mark as unknown
        currentCorrectAnswer = questionDetails.answer || questionDetails.options[0]; // Fallback, could be improved
      }
      
      const isActuallyCorrect = result.userAnswer !== null && result.userAnswer === currentCorrectAnswer;

      if (isActuallyCorrect) {
        calculatedScore += 1;
      } else if (input.testConfiguration.enableNegativeMarking && result.userAnswer !== null) {
        calculatedScore -= input.testConfiguration.negativeMarkValue;
      }
      return {
        ...result,
        correctAnswer: currentCorrectAnswer, // Use validated/corrected answer
        isCorrect: isActuallyCorrect, // Re-evaluate based on potentially corrected answer
      };
    });

    // Ensure score doesn't go below 0
    calculatedScore = Math.max(0, calculatedScore);

    return {
      results: finalResults,
      score: calculatedScore,
      totalQuestions: input.questions.length,
    };
  }
);
